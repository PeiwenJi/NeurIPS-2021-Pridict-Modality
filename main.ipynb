{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01eccde6-5b5f-4f40-9853-ef127c50a259",
   "metadata": {},
   "source": [
    "# My Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96327378-2489-4a3f-83a0-b5897d7f949f",
   "metadata": {},
   "source": [
    "## 1. data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02aaee8-69cb-443b-b7f4-c4bf689c0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_reader import read_train_data,read_test_data\n",
    "from scripts.evaluate import evaluate\n",
    "from config import config\n",
    "import pandas as pd\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1f313f-006c-4b29-a713-e79d70ab6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_mod1, input_train_mod2 = read_train_data(config)\n",
    "input_test_mod1, input_test_mod2 = read_test_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d212a48-36f3-4a9a-bb3a-e43bde85ba9b",
   "metadata": {},
   "source": [
    "## 2. train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7c8ce1-2fe5-4c83-95d0-d158fdc9af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = ad.concat(\n",
    "    {\"train\": input_train_mod1, \"test\": input_test_mod1},\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    label=\"group\",\n",
    "    fill_value=0,\n",
    "    index_unique=\"-\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23fcbf8-3376-474f-a28a-181f2d2bf98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 500 × 600\n",
       "    obs: 'batch', 'size_factors', 'group'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15609f9-b345-4b53-b277-76fd4af97177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 221 × 600\n",
       "    obs: 'batch', 'size_factors'\n",
       "    var: 'feature_types'\n",
       "    uns: 'dataset_id', 'gene_activity_var_names', 'organism'\n",
       "    obsm: 'gene_activity'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train_mod2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d811df-6761-4d84-a696-237d358a60ba",
   "metadata": {},
   "source": [
    "## 3. VAE reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ff2e83-9139-4d97-80e9-85b7a24a26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6d14bb-013b-48c1-9fc3-c9234d9672c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        # 编码器\n",
    "        self.fc1 = nn.Linear(input_dim, 400)\n",
    "        self.fc21 = nn.Linear(400, latent_dim)\n",
    "        self.fc22 = nn.Linear(400, latent_dim)\n",
    "        # 解码器\n",
    "        self.fc3 = nn.Linear(latent_dim, 400)\n",
    "        self.fc4 = nn.Linear(400, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, input_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar, z\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # KL散度\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d852835b-8289-405e-8f82-943ba50ab17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 input_train 和 input_train_mod2 是 NumPy 数组或 Pandas DataFrame\n",
    "tensor_x = torch.Tensor(input_train.X.toarray())  # 转换 input_train\n",
    "tensor_y = torch.Tensor(input_train_mod2.X.toarray())      # 转换 input_train_mod2\n",
    "\n",
    "# 创建数据加载器\n",
    "dataset_x = TensorDataset(tensor_x) \n",
    "dataset_y = TensorDataset(tensor_y)\n",
    "\n",
    "loader_x = DataLoader(dataset_x, batch_size=32, shuffle=True)\n",
    "loader_y = DataLoader(dataset_y, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3daca136-371a-4a4d-89c7-bef8223d03af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 197.69783837890625\n",
      "Epoch 1, Loss: 159.724333984375\n",
      "Epoch 2, Loss: 156.34261767578124\n",
      "Epoch 3, Loss: 155.1858876953125\n",
      "Epoch 4, Loss: 154.1045732421875\n",
      "Epoch 5, Loss: 153.31967138671874\n",
      "Epoch 6, Loss: 152.47911669921876\n",
      "Epoch 7, Loss: 151.53439892578126\n",
      "Epoch 8, Loss: 150.872818359375\n",
      "Epoch 9, Loss: 150.251142578125\n",
      "Epoch 0, Loss: 55.94428369140625\n",
      "Epoch 1, Loss: 36.80267626953125\n",
      "Epoch 2, Loss: 29.672128662109376\n",
      "Epoch 3, Loss: 27.81671630859375\n",
      "Epoch 4, Loss: 27.03416650390625\n",
      "Epoch 5, Loss: 26.806733154296875\n",
      "Epoch 6, Loss: 26.699676513671875\n",
      "Epoch 7, Loss: 26.542757568359374\n",
      "Epoch 8, Loss: 26.499392578125\n",
      "Epoch 9, Loss: 26.44298291015625\n"
     ]
    }
   ],
   "source": [
    "# 设定输入维度和潜在空间维度\n",
    "input_dim = input_train_mod1.shape[1] \n",
    "input_dim_x = input_train.shape[1]\n",
    "input_dim_y = input_train_mod2.shape[1]\n",
    "latent_dim = 50  # 潜在空间维度\n",
    "\n",
    "# 初始化两个模型\n",
    "model_x = VAE(input_dim_x, latent_dim)\n",
    "model_y = VAE(input_dim_y, latent_dim)\n",
    "\n",
    "# 训练模型（以 model_x 为例）\n",
    "optimizer_x = torch.optim.Adam(model_x.parameters(), lr=1e-3)\n",
    "epochs = 10  # 迭代次数\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_x.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data,) in enumerate(loader_x):\n",
    "        optimizer_x.zero_grad()\n",
    "        recon_batch, mu, logvar, z = model_x(data)\n",
    "        loss = vae_loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer_x.step()\n",
    "    print(f'Epoch {epoch}, Loss: {train_loss / len(loader_x.dataset)}')\n",
    "\n",
    "optimizer_y = torch.optim.Adam(model_y.parameters(), lr=1e-3)\n",
    "epochs = 10  # 迭代次数\n",
    "\n",
    "# 对 model_y 重复上述训练过程\n",
    "for epoch in range(epochs):\n",
    "    model_y.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data,) in enumerate(loader_y):\n",
    "        optimizer_y.zero_grad()\n",
    "        recon_batch, mu, logvar, z = model_y(data)\n",
    "        loss = vae_loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer_y.step()\n",
    "    print(f'Epoch {epoch}, Loss: {train_loss / len(loader_x.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2824e858-30a2-4134-bcce-e6cda4856fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x.eval()\n",
    "with torch.no_grad():\n",
    "    latent_x = [model_x.encode(data) for data, in loader_x]\n",
    "\n",
    "# 对 model_y 重复上述降维过程\n",
    "model_y.eval()\n",
    "with torch.no_grad():\n",
    "    latent_y = [model_y.encode(data.view(-1, input_dim_y))[0].numpy() for data, in loader_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a7296b-88af-4d6b-ad9b-ae7b18692b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_x = []\n",
    "with torch.no_grad():\n",
    "    for idx, [x] in enumerate(loader_x):\n",
    "        #x = x.to(device)\n",
    "        _, _, _, z = model_x(x)\n",
    "        tensors_x.append(z)\n",
    "\n",
    "concatenated_tensor_x = torch.cat(tensors_x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115f5c93-7f42-4398-8665-eeb90a857a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_tensor_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91844d06-41f2-43f1-9636-c0568045c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_y = []\n",
    "with torch.no_grad():\n",
    "    for idx, [y] in enumerate(loader_y):\n",
    "        #x = x.to(device)\n",
    "        _, _, _, z = model_y(y)\n",
    "        tensors_y.append(z)\n",
    "\n",
    "concatenated_tensor_y = torch.cat(tensors_y, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4700cf52-afa8-4635-9b91-86c55672977d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([221, 50])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_tensor_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa781f-2dd3-4092-a007-83ced388b364",
   "metadata": {},
   "source": [
    "## 4. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "978abf06-bec3-4775-8d79-86e65a76ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e09bdb3-9f43-4271-9fdc-1f2ad7228662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = concatenated_tensor_x[input_train.obs['group'] == 'train']\n",
    "X_test = concatenated_tensor_x[input_train.obs['group'] == 'test']\n",
    "y_train = concatenated_tensor_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b8e9dd9-0a31-46bc-9725-0f1c65d0a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_train) + len(X_test) == len(concatenated_tensor_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1c8811f-f5e5-4efe-9f7c-025f802e03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor()\n",
    "\n",
    "# Train the model on the PCA reduced modality 1 and 2 data\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b86b38ad-202c-4d00-92b0-38461e6f728d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ff976-356a-4667-b0c8-403f4db32394",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d7aca30-287f-42af-ba0f-f4c9fb7f13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_y_pred = torch.Tensor(input_test_mod1.X.toarray()) \n",
    "dataset_y_pred = TensorDataset(tensor_y_pred)\n",
    "loader_y_pred = DataLoader(dataset_y_pred, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1311867-73f9-460d-b241-a019d0fc0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = []\n",
    "with torch.no_grad():\n",
    "    for idx, [y_pred] in enumerate(loader_y_pred):\n",
    "        #x = x.to(device)\n",
    "        recon_y_pred, _, _, _ = model_y(y_pred)\n",
    "        tensors.append(recon_y_pred)\n",
    "\n",
    "concatenated_tensor = torch.cat(tensors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b98af581-d7a4-4397-bb85-900d87749ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 600)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_tensor.numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970b339-3406-4f2e-8fdc-f06c03fed5d5",
   "metadata": {},
   "source": [
    "## 6. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7b92399-4a53-450a-9d28-10b0c1a6acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9ab67ed-dfa6-4c35-b18c-f9c14a693381",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = csc_matrix(concatenated_tensor.numpy())\n",
    "\n",
    "if config[\"save_predict\"]:\n",
    "    out = ad.AnnData(\n",
    "        X=prediction,\n",
    "        obs=input_test_mod1.obs,\n",
    "        var=input_train_mod2.var,\n",
    "        uns={\n",
    "            'dataset_id': input_train_mod1.uns['dataset_id'],\n",
    "            'method_id': config[\"method_name\"],\n",
    "        },\n",
    "    )\n",
    "    out.write_h5ad(config[\"output\"], compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e501482-4d6d-4a58-a9bb-81515528b2b4",
   "metadata": {},
   "source": [
    "## 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce7fc6ae-851b-4c06-8f8c-4fb8a1c2e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.evaluate import evaluate\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fc6fbc5-8be0-4a12-967a-c6f30ed9ae28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.32230380177497864\n",
      "MAE: 0.21604646742343903\n"
     ]
    }
   ],
   "source": [
    "if config[\"do_test\"]:\n",
    "    result = evaluate(prediction, input_test_mod2.X)\n",
    "\n",
    "if config[\"write_result\"]:\n",
    "    pd.DataFrame([result]).to_csv(config[\"output\"].replace(\"h5ad\",\"csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21354b83-540d-422e-b876-39072fbd2dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
